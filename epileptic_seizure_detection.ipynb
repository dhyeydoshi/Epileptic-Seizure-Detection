{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "p3q_PZ9gWCNd",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-31T16:59:10.773481Z",
     "start_time": "2024-03-31T16:59:10.710441Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_auc_score , accuracy_score , precision_score, recall_score ,confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import h5py\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "id": "sqK2xi7KWRZo",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-31T16:51:46.661960Z",
     "start_time": "2024-03-31T16:51:46.651065Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/Epileptic Seizure Recognition.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.describe(include=object)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "null_values = data.isnull().sum()\n",
    "null_values.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_1 = data.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_1.drop(['Unnamed','y'],axis=1,inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, sharex=True, sharey=True)\n",
    "fig.set_size_inches(18, 24)\n",
    "labels = [\"X20\",\"X40\",\"X60\",\"X80\",\"X100\"]\n",
    "colors = [\"b\",\"g\",\"k\",\"r\",\"y\"]\n",
    "fig.suptitle('Visual representation of different channels when stacked independently', fontsize = 20)\n",
    "for i,ax in enumerate(axs):\n",
    "  axs[i].plot(data.iloc[:,0],data[labels[i]],color=colors[i],label=labels[i])\n",
    "  axs[i].legend(loc=\"upper right\")\n",
    "\n",
    "\n",
    "plt.xlabel('total number of observation', fontsize = 20)\n",
    "x_ticks = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000]\n",
    "x_ticklabels = ['0', '1000', '2000', '3000', '4000', '5000', '6000', '7000', '8000', '9000', '10000', '11000', '12000']\n",
    "plt.xticks(x_ticks, x_ticklabels)\n",
    "plt.savefig(os.path.join(BASE_DIR, 'static/assets/img', 'independent_channel.png'))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "data.loc[:,::25].plot()\n",
    "plt.title(\"Visual representation different channels when stacked against each other\")\n",
    "plt.xlabel(\"total number of values of x\")\n",
    "plt.ylabel(\"range of values of y\")\n",
    "plt.savefig(os.path.join(BASE_DIR, 'static/assets/img', 'stacked_channels.png'))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr = data_1.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap='coolwarm'\n",
    ")\n",
    "plt.title(\"Heat Map\")\n",
    "plt.savefig(os.path.join(BASE_DIR, 'static/assets/img','heat_map.png'))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Solve Class Imbalance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_2 = data.drop([\"Unnamed\"],axis=1).copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_2.y.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_2['y'] = data_2['y'].replace([2,3,4,5],0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_2.y.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_2.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6),dpi=300)\n",
    "sns.despine(left=True)\n",
    "sns.scatterplot(x='X1', y='X2', hue = 'y', data=data_2, palette=['red', 'blue'])\n",
    "plt.title('Distribution of Labels')\n",
    "plt.legend(loc='upper left', title=\"labels\")\n",
    "plt.savefig(os.path.join(BASE_DIR, 'static/assets/img', 'scatter_plot.png'))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_2.y.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X  = data_2.drop(['y'], axis=1)\n",
    "y = data_2['y']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counter = Counter(y)\n",
    "print('Before',counter)\n",
    "smenn = SMOTEENN()\n",
    "X_train1, y_train1 = smenn.fit_resample(X, y)\n",
    "counter = Counter(y_train1)\n",
    "print('After',counter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save data for using in Django\n",
    "X_train1.to_csv(os.path.join(BASE_DIR, 'data', 'data.csv'), index=False)\n",
    "y_train1.to_csv(os.path.join(BASE_DIR,'data', 'labels.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train/Test/Validation Dataset Splitting\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train1,y_train1,test_size=0.2,random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.25,random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Scaling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"The shape of the training set is :{X_train.shape}\")\n",
    "print(f\"The shape of the testing set is :{X_test.shape}\")\n",
    "print(f\"The shape of the validation set is :{X_val.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save Logistic Regression Model\n",
    "lg_filename = 'LogisticRegressionModel.pickle'\n",
    "with open(os.path.join(BASE_DIR, \"model\", lg_filename), 'wb') as f:\n",
    "    pickle.dump(logreg, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "y_pred = logreg.predict(X_val)\n",
    "print(f\"The accuracy score of the model on the validation data is:{metrics.accuracy_score(y_val, y_pred)*100:.2f}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models_dataframe = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression'],\n",
    "    'Score': [f'{metrics.accuracy_score(y_val, y_pred)*100:.2f}'],\n",
    "    'Precision': [f'{metrics.precision_score(y_val, y_pred)*100:.2f}'],\n",
    "    'F1_Score': [f'{metrics.f1_score(y_val, y_pred)*100:.2f}'],\n",
    "    'Recall': [f'{metrics.recall_score(y_val, y_pred)*100:.2f}'],\n",
    "    'View': ['LogisticView'],\n",
    "    'SavedModelName': [f'{lg_filename}']\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logit_fpr, logit_tpr, thresholds = metrics.roc_curve(y_val, y_pred)\n",
    "logit_auc = metrics.roc_auc_score(y_val, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe = Pipeline([('knn', KNeighborsClassifier())])\n",
    "param_grid = {'knn__n_neighbors': [9,10, 100]}\n",
    "knn = GridSearchCV(pipe, param_grid, cv=5)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "print('Best hyperparameters:', knn.best_params_)\n",
    "# Save KNN Model\n",
    "knn_filename = 'KNNModel.pickle'\n",
    "with open(os.path.join(BASE_DIR, \"model\", knn_filename), 'wb') as f:\n",
    "    pickle.dump(knn, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_val)\n",
    "knn_fpr, knn_tpr, thresholds = metrics.roc_curve(y_val, y_pred)\n",
    "knn_auc = metrics.roc_auc_score(y_val, y_pred)\n",
    "y_valid_preds = knn.predict_proba(X_val)\n",
    "precision = metrics.accuracy_score(y_pred=y_pred, y_true=y_val) * 100\n",
    "print(f\"Accuracy with K-NN: {precision:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_row = pd.DataFrame({\n",
    "    'Model': ['KNN'],\n",
    "    'Score': [f'{metrics.accuracy_score(y_val, y_pred)*100:.2f}'],\n",
    "    'Precision': [f'{metrics.precision_score(y_val, y_pred)*100:.2f}'],\n",
    "    'F1_Score': [f'{metrics.f1_score(y_val, y_pred)*100:.2f}'],\n",
    "    'Recall': [f'{metrics.recall_score(y_val, y_pred)*100:.2f}'],\n",
    "    'View': ['KNNView'],\n",
    "    'SavedModelName': [f'{knn_filename}']\n",
    "})\n",
    "if not models_dataframe.isin(new_row).all().all():\n",
    "    # If the new row values do not exist in the DataFrame, append the row\n",
    "    models_dataframe = models_dataframe.append(new_row, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Support Vector Machine"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='poly', C=100, gamma=0.01, probability=True)\n",
    "clf.fit(X_train, y_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save SVM Model\n",
    "svm_filename = 'SVMModel.pickle'\n",
    "with open(os.path.join(BASE_DIR, \"model\", svm_filename), 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "precision = metrics.accuracy_score(y_pred=y_pred, y_true=y_val) * 100\n",
    "print(f\"Accuracy with SVM: {precision:.2f}%\")\n",
    "probs = clf.predict_proba(X_val)\n",
    "probs = probs[:, 1]\n",
    "svm_fpr, svm_tpr, thresholds = metrics.roc_curve(y_val, probs)\n",
    "svm_auc = metrics.roc_auc_score(y_val, probs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_row = pd.DataFrame({\n",
    "    'Model': ['SVM'],\n",
    "    'Score': [f'{metrics.accuracy_score(y_val, y_pred)*100:.2f}'],\n",
    "    'Precision': [f'{metrics.precision_score(y_val, y_pred)*100:.2f}'],\n",
    "    'F1_Score': [f'{metrics.f1_score(y_val, y_pred)*100:.2f}'],\n",
    "    'Recall': [f'{metrics.recall_score(y_val, y_pred)*100:.2f}'],\n",
    "    'View': ['SVMView'],\n",
    "    'SavedModelName': [f'{svm_filename}']\n",
    "})\n",
    "if not models_dataframe.isin(new_row).all().all():\n",
    "    # If the new row values do not exist in the DataFrame, append the row\n",
    "    models_dataframe = models_dataframe.append(new_row, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Naive Bayes Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "naive = GaussianNB()\n",
    "naive.fit(X_train,y_train)\n",
    "# Save NaiveBayes Model\n",
    "nb_filename = 'NaiveBayesModel.pickle'\n",
    "with open(os.path.join(BASE_DIR, \"model\", nb_filename), 'wb') as f:\n",
    "    pickle.dump(naive, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = naive.predict(X_val)\n",
    "naive_fpr, naive_tpr, thresholds = metrics.roc_curve(y_val, y_pred)\n",
    "naive_auc = metrics.roc_auc_score(y_val, y_pred)\n",
    "print(f'Accuracy with naive is:{metrics.accuracy_score(y_pred=y_pred, y_true=y_val) * 100:.2f}%.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_row = pd.DataFrame({\n",
    "    'Model': ['Naive Bayes'],\n",
    "    'Score': [f'{metrics.accuracy_score(y_val, y_pred)*100:.2f}'],\n",
    "    'Precision': [f'{metrics.precision_score(y_val, y_pred)*100:.2f}'],\n",
    "    'F1_Score': [f'{metrics.f1_score(y_val, y_pred)*100:.2f}'],\n",
    "    'Recall': [f'{metrics.recall_score(y_val, y_pred)*100:.2f}'],\n",
    "    'View': ['NaiveBayesView'],\n",
    "    'SavedModelName': [f'{svm_filename}']\n",
    "})\n",
    "if not models_dataframe.isin(new_row).all().all():\n",
    "    # If the new row values do not exist in the DataFrame, append the row\n",
    "    models_dataframe = models_dataframe.append(new_row, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "random = RandomForestClassifier(max_depth=10,random_state=69)\n",
    "random.fit(X_train,y_train)\n",
    "\n",
    "# Save RF Model\n",
    "rf_filename = 'RandomForestModel.pickle'\n",
    "with open(os.path.join(BASE_DIR, \"model\", rf_filename), 'wb') as f:\n",
    "    pickle.dump(random, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#predicting\n",
    "y_pred = random.predict(X_val)\n",
    "random_fpr, random_tpr, thresholds = metrics.roc_curve(y_val, y_pred)\n",
    "random_auc = metrics.roc_auc_score(y_val, y_pred)\n",
    "#Evaluating the model\n",
    "precision = metrics.accuracy_score(y_pred=y_pred,y_true=y_val)* 100\n",
    "#print  the accuracy\n",
    "print(f\"Accuracy of the model by using the random forest algorithm : {precision:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_row = pd.DataFrame({\n",
    "    'Model': ['Random Forest'],\n",
    "    'Score': [f'{metrics.accuracy_score(y_val, y_pred)*100:.2f}'],\n",
    "    'Precision': [f'{metrics.precision_score(y_val, y_pred)*100:.2f}'],\n",
    "    'F1_Score': [f'{metrics.f1_score(y_val, y_pred)*100:.2f}'],\n",
    "    'Recall': [f'{metrics.recall_score(y_val, y_pred)*100:.2f}'],\n",
    "    'View': ['RandomForestView'],\n",
    "    'SavedModelName': [f'{rf_filename}']\n",
    "})\n",
    "if not models_dataframe.isin(new_row).all().all():\n",
    "    # If the new row values do not exist in the DataFrame, append the row\n",
    "    models_dataframe = models_dataframe.append(new_row, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### XgBoost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier()\n",
    "\n",
    "xgbc.fit(X_train,y_train)\n",
    "\n",
    "# Save SVM Model\n",
    "xg_filename = 'XgBoostModel.pickle'\n",
    "with open(os.path.join(BASE_DIR, \"model\", xg_filename), 'wb') as f:\n",
    "    pickle.dump(xgbc, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#predicting\n",
    "y_pred = xgbc.predict(X_val)\n",
    "xgbc_fpr, xgbc_tpr, thresholds = metrics.roc_curve(y_val, y_pred)\n",
    "xgbc_auc = metrics.roc_auc_score(y_val, y_pred)\n",
    "#Evaluating the model\n",
    "precision = metrics.accuracy_score(y_pred=y_pred,y_true=y_val)* 100\n",
    "#print  the accuracy\n",
    "print(f\"Accuracy of the model by using the xgbc algorithm : {precision:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_row = pd.DataFrame({\n",
    "    'Model': ['XgBoost'],\n",
    "    'Score': [f'{metrics.accuracy_score(y_val, y_pred)*100:.2f}'],\n",
    "    'Precision': [f'{metrics.precision_score(y_val, y_pred)*100:.2f}'],\n",
    "    'F1_Score': [f'{metrics.f1_score(y_val, y_pred)*100:.2f}'],\n",
    "    'Recall': [f'{metrics.recall_score(y_val, y_pred)*100:.2f}'],\n",
    "    'View': ['XgBoostView'],\n",
    "    'SavedModelName': [f'{xg_filename}']\n",
    "})\n",
    "if not models_dataframe.isin(new_row).all().all():\n",
    "    # If the new row values do not exist in the DataFrame, append the row\n",
    "    models_dataframe = models_dataframe.append(new_row, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ROC Curve"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6),dpi=300)\n",
    "plt.title('ROC Curve')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.plot(logit_fpr, logit_tpr, 'c', marker='.', label = 'logit = %0.3f' % logit_auc )\n",
    "plt.plot(svm_fpr, svm_tpr, 'b', marker='.', label = 'SVM = %0.3f' % svm_auc )\n",
    "plt.plot(knn_fpr, knn_tpr, 'g', marker='.', label = 'K-NN = %0.3f' % knn_auc)\n",
    "plt.plot(naive_fpr, naive_tpr, 'm', marker='.', label = 'naive = %0.3f' % naive_auc)\n",
    "plt.plot(random_fpr, random_tpr, 'k', marker='.',label = 'Random Forest = %.3f' % random_auc)\n",
    "plt.plot(xgbc_fpr, xgbc_tpr, 'y', marker='.',label = 'XGBoost = %.3f' % xgbc_auc)\n",
    "\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig(os.path.join(BASE_DIR, 'static/assets/img', 'roc_curve.png'), dpi=100)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deep Learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001,\n",
    "    patience=20,\n",
    "    restore_best_weights=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(layers.Reshape((178, 1, 1), input_shape=(178,)))\n",
    "model1.add(layers.Conv2D(filters=32, kernel_size=(10, 1), activation='relu', input_shape=(178, 1, 1)))\n",
    "model1.add(layers.MaxPooling2D(pool_size=(3, 1)))\n",
    "model1.add(layers.Conv2D(filters=64, kernel_size=(10, 1), activation='relu'))\n",
    "model1.add(layers.MaxPooling2D(pool_size=(3, 1)))\n",
    "model1.add(layers.Flatten())\n",
    "model1.add(layers.Dense(units=64, activation='relu'))\n",
    "model1.add(layers.Dropout(0.5))\n",
    "model1.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# model Summary\n",
    "model1.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model1.compile(loss='binary_crossentropy',\n",
    "               optimizer=Adam(learning_rate=0.001),\n",
    "               metrics=['accuracy',  Precision(), Recall()])\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model1.fit(X_train, y_train,\n",
    "                     epochs=500,\n",
    "                     batch_size=32,\n",
    "                     validation_data=(X_val, y_val), callbacks=[early_stopping])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cnn_model_name = 'DeepLearning.h5'\n",
    "model1.save(os.path.join(BASE_DIR, 'model', cnn_model_name))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate the model on the data\n",
    "test_loss, test_acc, test_precision, test_recall = model1.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = model1.predict(X_val)\n",
    "print(\"Predictions\",predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert predictions to binary class labels\n",
    "y_pred_labels = [1 if x > 0.5 else 0 for x in predictions]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_row = pd.DataFrame({\n",
    "    'Model': ['CNN'],\n",
    "    'Score': [f'{test_acc*100:.2f}'],\n",
    "    'Precision': f'{test_precision*100:.2f}',\n",
    "    'F1_Score': [f'{metrics.f1_score(y_val, y_pred_labels)*100:.2f}'],\n",
    "    'Recall': f'{test_recall*100:.2f}',\n",
    "    'View': ['CNNView'],\n",
    "    'SavedModelName': [f'{cnn_model_name}']\n",
    "})\n",
    "if not models_dataframe.isin(new_row).all().all():\n",
    "    # If the new row values do not exist in the DataFrame, append the row\n",
    "    models_dataframe = models_dataframe.append(new_row, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(models_dataframe.sort_values('Score', ascending=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving the models later used by Django"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models_dataframe.sort_values('Score', ascending=False).to_csv(os.path.join(BASE_DIR, 'data', 'model_acc_dataframe.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "temp_data = data.drop(['y'], axis=1).copy()\n",
    "temp_data1 = temp_data[temp_data['Unnamed'].str.split('.').str[2] == '941'].copy()\n",
    "temp_data1"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_x = temp_data1.drop(['Unnamed'], axis=1).copy()\n",
    "data_x = scaler.transform(data_x)\n",
    "pre = model1.predict(data_x)\n",
    "pre"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "binary_predictions = [1 if pr > 0.5 else 0 for pr in pre]\n",
    "print(binary_predictions)\n",
    "threshold = 0.5\n",
    "\n",
    "# Apply threshold and classify patient's output\n",
    "predicted_class = 1 if np.mean(binary_predictions) >= threshold else 0\n",
    "\n",
    "print(predicted_class)\n",
    "if predicted_class == 1:\n",
    "    output_string = f\"The patient is predicted to have epilepsy.\"\n",
    "else:\n",
    "    output_string = f\"The patient is predicted to not have epilepsy.\"\n",
    "print(output_string)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ]
}
